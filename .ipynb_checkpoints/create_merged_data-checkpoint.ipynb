{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M = pd.read_csv(\"predictions_all.csv\")\n",
    "left = pd.read_csv(\"ltable_amazon.csv\",encoding = \"ISO-8859-1\")\n",
    "right = pd.read_csv(\"rtable_walmart.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# amazon->wamart matches\n",
    "# wamart->amazon matches\n",
    "amazon_to_walmart_mapper = {}\n",
    "walmart_to_amazon_mapper = {}\n",
    "\n",
    "for index, row in left.iterrows():\n",
    "    left_id = row['id']\n",
    "    #Find list of matches\n",
    "    match = M.loc[(M['ltable_id'] == left_id)  & (M['predicted_labels'] == 1)]\n",
    "    if match.empty:\n",
    "        #No match exists for walmart ids add key-> emptylist\n",
    "        amazon_to_walmart_mapper[left_id] = []\n",
    "    else:\n",
    "        # Match exist\n",
    "        match_list= match.iloc[:, 2].tolist()\n",
    "        amazon_to_walmart_mapper[left_id] = match_list\n",
    "\n",
    "# Do the same thing for walmart dataset\n",
    "for index, row in right.iterrows():\n",
    "    right_id = row['id']\n",
    "    #Find list of matches\n",
    "    match = M.loc[(M['rtable_id'] == right_id) & (M['predicted_labels'] == 1)]\n",
    "    if match.empty:\n",
    "        #No match exists for walmart ids add key-> emptylist\n",
    "        walmart_to_amazon_mapper[right_id] = []\n",
    "    else:\n",
    "        # Match exist\n",
    "        match_list= match.iloc[:, 1].tolist()\n",
    "        walmart_to_amazon_mapper[right_id] = match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    wids = []\n",
    "    aids = []\n",
    "    \n",
    "    def __init__(self, aids, wids):\n",
    "        self.aids = aids\n",
    "        self.wids = wids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create list to manage duplicates \n",
    "wids_touched = []\n",
    "aids_touched = []\n",
    "clusters = [] #List of clusters\n",
    "\n",
    "for key, values in amazon_to_walmart_mapper.items():\n",
    "    aids = []\n",
    "    wids = []\n",
    "    if key not in aids_touched:\n",
    "        aids.append(key)\n",
    "        aids_touched.append(key)\n",
    "        wids.extend(values)\n",
    "        wids_touched.extend(values)\n",
    "        for w_id in values:\n",
    "            if w_id in walmart_to_amazon_mapper:\n",
    "                a_list = walmart_to_amazon_mapper[w_id]\n",
    "                for val in a_list:\n",
    "                    if val not in aids_touched:\n",
    "                        aids_touched.append(val)\n",
    "                        aids.append(val)\n",
    "    clusters.append(Cluster(list(set(aids)),list(set(wids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we have the custers of matches, let's start merging\n",
    "# Name - MaxLength\n",
    "# Price - Exists/Max\n",
    "# Category - Amazon Category\n",
    "# Author - MaxLength\n",
    "# ISBN - Exists/Amazon has preference\n",
    "# Pages - Max\n",
    "# Publisher - Exists/ Amazon has preference\n",
    "# Language - exists/Amazon\n",
    "# Dimensions - esists/Amazon has preference\n",
    "# Weight - Amazon\n",
    "# Rating - MinRating\n",
    "#M.loc[(M['rtable_id'] == right_id) & (M['predicted_labels'] == 1)]\n",
    "with open(\"merged_table.csv\", \"w\", newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    writer.writerow([\"Name\",\"Sale Price\",\"Category\",\"Author\",\"ISBN10\",\"Pages\",\n",
    "                     \"Publisher\",\"Language\",\"Dimensions\",\"Weight\",\"Rating\"])\n",
    "    for cluster in clusters:\n",
    "        max_name = \"\"\n",
    "        max_price = 0\n",
    "        category = \"\"\n",
    "        max_author = \"\"\n",
    "        isbn = \"\"\n",
    "        max_pages = 0\n",
    "        publisher = \"\"\n",
    "        language = \"\"\n",
    "        dimensions = \"\"\n",
    "        weight = \"\"\n",
    "        rating = 100\n",
    "        if cluster.aids and cluster.wids:\n",
    "        \n",
    "            for a_id in cluster.aids:\n",
    "                if len(left['Name'][a_id]) > len(max_name):\n",
    "                    max_name = left['Name'][a_id]\n",
    "                if np.isnan(left['Sale Price'][a_id]) == False and \n",
    "                float(left['Sale Price'][a_id]) > float(max_price):\n",
    "                    max_price = float(left['Sale Price'][a_id])\n",
    "                if len(left['Category'][a_id]) > len(category):\n",
    "                    category = left['Category'][a_id]\n",
    "                if len(left['Author'][a_id]) > len(max_author):\n",
    "                    max_author = left['Author'][a_id]\n",
    "                if len(isbn) == 0:\n",
    "                    isbn = left['ISBN10'][a_id]\n",
    "                if np.isnan(left['Pages'][a_id]) == False and \n",
    "                int(left['Pages'][a_id]) > int(max_pages):\n",
    "                    max_pages = int(left['Pages'][a_id])\n",
    "                if len(publisher) == 0:\n",
    "                    publisher = left['Publisher'][a_id]\n",
    "                if len(language) == 0:\n",
    "                    language = left['Language'][a_id]\n",
    "                if len(dimensions) == 0 and left['Dimensions'][a_id] != \"nan\":\n",
    "                    dimensions = left['Dimensions'][a_id]\n",
    "                    if isinstance(dimensions, str) == False: dimensions = \"\"\n",
    "                if len(weight) == 0:\n",
    "                    weight = left['Weight'][a_id]\n",
    "                if np.isnan(left['Rating'][a_id]) == False and \n",
    "                int(left['Rating'][a_id]) < int(rating):\n",
    "                    rating = int(left['Rating'][a_id])\n",
    "            \n",
    "            for w_id in cluster.wids:\n",
    "                if len(right['Name'][w_id]) > len(max_name):\n",
    "                    max_name = right['Name'][w_id] \n",
    "                if np.isnan(right['Sale Price'][w_id]) == False and \n",
    "                float(right['Sale Price'][w_id]) > float(max_price):\n",
    "                    max_price = float(right['Sale Price'][w_id])\n",
    "                if len(right['Author'][w_id]) > len(max_author):\n",
    "                    max_author = right['Author'][w_id] \n",
    "                if len(isbn) == 0:\n",
    "                    isbn = right['ISBN10'][w_id]\n",
    "                if np.isnan(right['Pages'][w_id]) == False and \n",
    "                int(right['Pages'][w_id]) > int(max_pages):\n",
    "                    max_pages = int(right['Pages'][w_id])\n",
    "                if len(publisher) == 0:\n",
    "                    publisher = right['Publisher'][w_id]\n",
    "                if len(language) == 0:\n",
    "                    language = right['Language'][w_id]\n",
    "                if len(dimensions) == 0 :\n",
    "                    dimensions = right['Dimensions'][w_id]\n",
    "                if np.isnan(right['Rating'][w_id]) == False and \n",
    "                int(right['Rating'][w_id]) < int(rating):\n",
    "                    rating = int(right['Rating'][w_id])\n",
    "            if rating == 100:\n",
    "                rating = math.nan\n",
    "            if max_price == 0:\n",
    "                max_price = math.nan\n",
    "            if max_pages == 0:\n",
    "                max_pages = math.nan\n",
    "            writer.writerow([max_name, max_price, category, max_author, isbn, \n",
    "                             max_pages, publisher, language, dimensions, \n",
    "                             weight, rating])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
